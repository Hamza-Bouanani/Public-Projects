{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real or Fake, on Collab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNA8Sdx32D3Vk0qNrK5zNvh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza-Bouanani/Public-Projects/blob/main/Kaggle/Real_or_Not/With_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ug8DAUzkB3x"
      },
      "source": [
        "Tout d'abord on utilise une accÃ©lÃ©ration matÃ©riel avec le GPU donnÃ© par Colab.\n",
        "Pour faire cela : \n",
        "Edit ðŸ¡’ Notebook Settings ðŸ¡’ Hardware accelerator ðŸ¡’ (GPU)\n",
        "Ensuite, vÃ©rifier si cela a bien Ã©tÃ© fait en exÃ©cutant le code suivant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxYQ2bndj_Mp",
        "outputId": "d140c323-11fc-45ca-9bf0-0c08d1bc6a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name() \n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhijaXzhkYVY"
      },
      "source": [
        "Maintenant, on va forcer torch Ã  utiliser le GPU dont on dispose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hafj7Nmbk7S-",
        "outputId": "405a3fc4-f590-41f5-b504-c09acc122a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qHZBqLfkVY2",
        "outputId": "137d5049-bcce-44b9-d538-4e9e260b236b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\r\u001b[K     |â–Ž                               | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |â–‹                               | 20kB 6.7MB/s eta 0:00:01\r\u001b[K     |â–ˆ                               | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Ž                              | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Œ                              | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–‰                              | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–                             | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–Œ                             | 81kB 8.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–‰                             | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆ                             | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–                            | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Š                            | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆ                            | 133kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 143kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 153kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 163kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 174kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 184kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 194kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 204kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 215kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 225kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 235kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 245kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 256kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 266kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 276kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 286kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 296kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 307kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 317kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 327kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 337kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 348kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 358kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 368kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 378kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 389kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 399kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 409kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 419kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 430kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 440kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 450kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 460kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 471kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 481kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 491kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 501kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 512kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 522kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 532kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 542kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 552kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 563kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 573kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 583kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 593kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 604kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 614kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 624kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 634kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 645kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 655kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 665kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 675kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 686kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 696kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 706kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 716kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 727kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 737kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 747kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 757kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 768kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 778kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 788kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 798kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 808kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 819kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 829kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 839kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 849kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 860kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 870kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 880kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 890kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 901kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 911kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 921kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 931kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 942kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 952kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 962kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 972kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 983kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 993kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.1MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 53.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=06d2095bddc4bde39d92e15d73f449de62cef00e66a3fe398f337c8408228ac2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMX3ideBl7bH"
      },
      "source": [
        "Pour importer un fichier depuis mon disque local sur google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufqGKniclMwy",
        "outputId": "1e875c9b-e5d2-4672-b5ca-4055e0b8eacb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78af1831-04ec-4f05-b3ff-abf425db4465\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78af1831-04ec-4f05-b3ff-abf425db4465\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WKnbONrmCiO"
      },
      "source": [
        "### lecture des donnÃ©es ####\n",
        "import pandas as pd\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKZbgw43lanK"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4seqfixkaK-"
      },
      "source": [
        "# Traitement des donnÃ©es\n",
        "def no_at(text):\n",
        "    p = re.compile(r'\\s')\n",
        "    l = p.split(text)\n",
        "    for mot in l :\n",
        "        if '@' in mot :\n",
        "            l.remove(mot)\n",
        "    text_final = ''\n",
        "    for mot in l:\n",
        "        text_final +=mot\n",
        "        text_final += ' '\n",
        "    return text_final\n",
        "\n",
        "for i in range(2):\n",
        "    train['text_cleaned'] = train['text'].apply(no_at)\n",
        "    test['text_cleaned'] = test['text'].apply(no_at)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSEqJ8ilmOaF"
      },
      "source": [
        "# On sÃ©pare le text et les labels\n",
        "train_text = train.text_cleaned.values\n",
        "labels = train.target.values\n",
        "\n",
        "test_text = test.text_cleaned.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdA59aVlmmTN",
        "outputId": "15e56df0-d6f9-4d9d-f022-7af2aa677c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odDdvSKTmqit",
        "outputId": "b5949b70-d84d-4f5d-fdf3-97b2d32d6595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Pour voir un exemple de tokenizing\n",
        "print(' Original: ', train_text[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(train_text[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_text[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all \n",
            "Tokenized:  ['our', 'deeds', 'are', 'the', 'reason', 'of', 'this', '#', 'earthquake', 'may', 'allah', 'forgive', 'us', 'all']\n",
            "Token IDs:  [2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgEfxl6Fm5zk"
      },
      "source": [
        "Il faut dÃ©finir un max_len car BERT doit avoir toutes les instances de la mÃªme taille. Donc, on dÃ©finit la taille max de token prÃ©sent dans nos instances et on dÃ©finit un nombre un plus grand comme la taille de chaque instance et on complÃ¨te les instances avec moins de token que le max_len par des tokens qui ne font rien."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koy50UUMm2lv",
        "outputId": "3adfaa53-d1a5-4fcb-d73f-b92a9c787cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train_text:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnmNZy01nuJv",
        "outputId": "955ae691-a634-4585-b51d-4c82dab2f294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train_text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 83,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt', # Return pytorch tensors.\n",
        "                        truncation=True  ,  \n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_text[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all \n",
            "Token IDs: tensor([  101,  2256, 15616,  2024,  1996,  3114,  1997,  2023,  1001,  8372,\n",
            "         2089, 16455,  9641,  2149,  2035,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDruUuBYn0ZR",
        "outputId": "aa772921-00bb-4136-d6e4-0ad115f3e44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6,851 training samples\n",
            "  762 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1AzL5--n7MF"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbjVD_EgoUb3",
        "outputId": "3df3b546-3bf1-4dc6-d143-39cb945082d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE0nqSa5oWL4",
        "outputId": "59cae11d-b9a9-4bc9-a263-99c616408411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxhW-jcAoX9C"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1esqCoioaBD"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lse71NyGocOO"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IirL0WdEod2t"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4eVhmJCofB5",
        "outputId": "4ddd33e3-5273-447a-867c-4f71242d9326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    429.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    429.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    429.    Elapsed: 0:00:30.\n",
            "  Batch   160  of    429.    Elapsed: 0:00:40.\n",
            "  Batch   200  of    429.    Elapsed: 0:00:50.\n",
            "  Batch   240  of    429.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    429.    Elapsed: 0:01:11.\n",
            "  Batch   320  of    429.    Elapsed: 0:01:21.\n",
            "  Batch   360  of    429.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    429.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:01:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    429.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    429.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    429.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    429.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    429.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    429.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    429.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    429.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    429.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    429.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.42\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    429.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    429.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    429.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    429.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    429.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    429.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    429.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    429.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    429.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    429.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:01:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    429.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    429.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    429.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    429.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    429.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    429.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    429.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    429.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    429.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    429.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:01:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.70\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:33 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7qyjNnWEkGe"
      },
      "source": [
        "RÃ©sumÃ© du train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4zfREPsEmAL",
        "outputId": "e0f2c786-087b-4e03-fb61-4740fc4f7847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:01:49</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:01:50</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:01:50</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:49</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.45         0.39           0.84       0:01:49         0:00:04\n",
              "2               0.31         0.42           0.85       0:01:50         0:00:04\n",
              "3               0.20         0.60           0.84       0:01:50         0:00:04\n",
              "4               0.12         0.70           0.83       0:01:49         0:00:04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNP1X6pBE436",
        "outputId": "a0054bee-5e00-48dc-be4d-b2a8e3c95b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZOBgF_hgvZs"
      },
      "source": [
        "labels = [0 for i in range(len(test_text))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3bzMZHfYfkX",
        "outputId": "2f3168c5-3335-4031-b8a1-6f43288a301c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# preparing the test\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "sentences = test_text\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h1bPV6fgT0s",
        "outputId": "9c3d385a-abcc-45a0-b2fb-dc7b2fe48db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,263 test sentences...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYZfU1C2hMRD"
      },
      "source": [
        "predict = []\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    predict.append(predictions[i][j])\n",
        "\n",
        "final_pred = []\n",
        "pred0 = []\n",
        "pred1 = []\n",
        "for pred in predict :\n",
        "  if pred[0]>pred[1]:\n",
        "    final_pred.append(0)\n",
        "  else:\n",
        "    final_pred.append(1)\n",
        "  pred0.append(pred[0])\n",
        "  pred1.append(pred[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P6ZK5chid7k"
      },
      "source": [
        "# prepare submission\n",
        "idd = test['id']\n",
        "file_name = 'SubmissionV1.csv'\n",
        "df = pd.DataFrame(idd)\n",
        "df['target'] = final_pred\n",
        "print(df)\n",
        "df.to_csv(file_name,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0VxKrkujwTy"
      },
      "source": [
        "# to download files stored in Colab\n",
        "files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}