{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real or Fake, on Collab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ug8DAUzkB3x"
      },
      "source": [
        "Tout d'abord on utilise une accÃ©lÃ©ration matÃ©riel avec le GPU donnÃ© par Colab.\n",
        "Pour faire cela : \n",
        "Edit ðŸ¡’ Notebook Settings ðŸ¡’ Hardware accelerator ðŸ¡’ (GPU)\n",
        "Ensuite, vÃ©rifier si cela a bien Ã©tÃ© fait en exÃ©cutant le code suivant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxYQ2bndj_Mp",
        "outputId": "c3f04441-bfc5-4af3-f588-61699db154a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name() \n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhijaXzhkYVY"
      },
      "source": [
        "Maintenant, on va forcer torch Ã  utiliser le GPU dont on dispose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hafj7Nmbk7S-",
        "outputId": "77fdb889-1b10-40b5-a989-c215eeedf650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qHZBqLfkVY2",
        "outputId": "137d5049-bcce-44b9-d538-4e9e260b236b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\r\u001b[K     |â–Ž                               | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |â–‹                               | 20kB 6.7MB/s eta 0:00:01\r\u001b[K     |â–ˆ                               | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Ž                              | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Œ                              | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–‰                              | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–                             | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–Œ                             | 81kB 8.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–‰                             | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆ                             | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–                            | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Š                            | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆ                            | 133kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 143kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 153kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 163kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 174kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 184kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 194kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 204kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 215kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 225kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 235kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 245kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 256kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 266kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 276kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 286kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 296kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 307kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 317kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 327kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 337kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 348kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 358kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 368kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 378kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 389kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 399kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 409kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 419kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 430kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 440kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 450kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 460kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 471kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 481kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 491kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 501kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 512kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 522kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 532kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 542kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 552kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 563kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 573kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 583kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 593kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 604kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 614kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 624kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 634kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 645kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 655kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 665kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 675kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 686kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 696kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 706kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 716kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 727kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 737kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 747kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 757kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 768kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 778kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 788kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 798kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 808kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 819kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 829kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 839kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 849kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 860kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 870kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 880kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 890kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 901kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 911kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 921kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 931kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 942kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 952kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 962kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 972kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 983kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 993kB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.1MB 9.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 53.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=06d2095bddc4bde39d92e15d73f449de62cef00e66a3fe398f337c8408228ac2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMX3ideBl7bH"
      },
      "source": [
        "Pour importer un fichier depuis mon disque local sur google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufqGKniclMwy",
        "outputId": "1e875c9b-e5d2-4672-b5ca-4055e0b8eacb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78af1831-04ec-4f05-b3ff-abf425db4465\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78af1831-04ec-4f05-b3ff-abf425db4465\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WKnbONrmCiO"
      },
      "source": [
        "### lecture des donnÃ©es ####\n",
        "import pandas as pd\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKZbgw43lanK"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4seqfixkaK-"
      },
      "source": [
        "# Traitement des donnÃ©es\n",
        "def no_at(text):\n",
        "    p = re.compile(r'\\s')\n",
        "    l = p.split(text)\n",
        "    for mot in l :\n",
        "        if '@' in mot :\n",
        "            l.remove(mot)\n",
        "    text_final = ''\n",
        "    for mot in l:\n",
        "        text_final +=mot\n",
        "        text_final += ' '\n",
        "    return text_final\n",
        "\n",
        "for i in range(2):\n",
        "    train['text_cleaned'] = train['text'].apply(no_at)\n",
        "    test['text_cleaned'] = test['text'].apply(no_at)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSEqJ8ilmOaF"
      },
      "source": [
        "# On sÃ©pare le text et les labels\n",
        "train_text = train.text_cleaned.values\n",
        "labels = train.target.values\n",
        "\n",
        "test_text = test.text_cleaned.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdA59aVlmmTN",
        "outputId": "c09659dc-1caa-4485-82a3-855039986672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odDdvSKTmqit",
        "outputId": "cfcc33da-1b94-492a-bd22-b81d70171418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Pour voir un exemple de tokenizing\n",
        "print(' Original: ', train_text[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(train_text[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_text[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all \n",
            "Tokenized:  ['our', 'deeds', 'are', 'the', 'reason', 'of', 'this', '#', 'earthquake', 'may', 'allah', 'forgive', 'us', 'all']\n",
            "Token IDs:  [2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgEfxl6Fm5zk"
      },
      "source": [
        "Il faut dÃ©finir un max_len car BERT doit avoir toutes les instances de la mÃªme taille. Donc, on dÃ©finit la taille max de token prÃ©sent dans nos instances et on dÃ©finit un nombre un plus grand comme la taille de chaque instance et on complÃ¨te les instances avec moins de token que le max_len par des tokens qui ne font rien."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koy50UUMm2lv",
        "outputId": "b22cfd3d-bc9c-4fae-e8ce-b3e0f95b2a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train_text:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnmNZy01nuJv",
        "outputId": "f37517f5-e42f-4479-f44b-78d4713d3d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train_text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 83,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt', # Return pytorch tensors.\n",
        "                        truncation=True  ,  \n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_text[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all \n",
            "Token IDs: tensor([  101,  2256, 15616,  2024,  1996,  3114,  1997,  2023,  1001,  8372,\n",
            "         2089, 16455,  9641,  2149,  2035,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDruUuBYn0ZR",
        "outputId": "8f07241b-58d8-4653-aef8-e54754934b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.95 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,232 training samples\n",
            "  381 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1AzL5--n7MF"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbjVD_EgoUb3",
        "outputId": "95c0052b-a779-4344-d10a-b77c4ca3ca85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE0nqSa5oWL4",
        "outputId": "6d133d35-ff75-47f7-fe92-a1ed4a6b3ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxhW-jcAoX9C"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1esqCoioaBD"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lse71NyGocOO"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IirL0WdEod2t"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4eVhmJCofB5",
        "outputId": "743f6397-324b-45b0-f3d3-68178c7c0a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    452.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    452.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    452.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    452.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    452.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    452.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    452.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    452.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    452.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    452.    Elapsed: 0:01:42.\n",
            "  Batch   440  of    452.    Elapsed: 0:01:53.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.41\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    452.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    452.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    452.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    452.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    452.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    452.    Elapsed: 0:01:02.\n",
            "  Batch   280  of    452.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    452.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    452.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    452.    Elapsed: 0:01:43.\n",
            "  Batch   440  of    452.    Elapsed: 0:01:53.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    452.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    452.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    452.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    452.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    452.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    452.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    452.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    452.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    452.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    452.    Elapsed: 0:01:42.\n",
            "  Batch   440  of    452.    Elapsed: 0:01:53.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:53 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7qyjNnWEkGe"
      },
      "source": [
        "RÃ©sumÃ© du train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4zfREPsEmAL",
        "outputId": "af822ed5-c02c-4d47-8a57-d0ea31b0dd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.43</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:56</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:01:56</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:01:56</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.43         0.41           0.83       0:01:56         0:00:02\n",
              "2               0.31         0.43           0.84       0:01:56         0:00:02\n",
              "3               0.24         0.51           0.84       0:01:56         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNP1X6pBE436",
        "outputId": "a412ff25-0293-404e-f6e6-6e239b590106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZOBgF_hgvZs"
      },
      "source": [
        "labels = [0 for i in range(len(test_text))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3bzMZHfYfkX",
        "outputId": "f8788aad-3c80-48dd-b76a-9020510a70db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# preparing the test\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "sentences = test_text\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h1bPV6fgT0s",
        "outputId": "6fd99d1a-4ce3-4826-91f1-744ce83456cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,263 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYZfU1C2hMRD"
      },
      "source": [
        "predict = []\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    predict.append(predictions[i][j])\n",
        "\n",
        "final_pred = []\n",
        "pred0 = []\n",
        "pred1 = []\n",
        "for pred in predict :\n",
        "  if pred[0]>pred[1]:\n",
        "    final_pred.append(0)\n",
        "  else:\n",
        "    final_pred.append(1)\n",
        "  pred0.append(pred[0])\n",
        "  pred1.append(pred[1])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P6ZK5chid7k",
        "outputId": "0fe2ede3-4d6c-4ea1-d88e-4d0638af4831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "# prepare submission\n",
        "idd = test['id']\n",
        "file_name = 'SubmissionV1.csv'\n",
        "df = pd.DataFrame(idd)\n",
        "df['target'] = final_pred\n",
        "print(df)\n",
        "df.to_csv(file_name,index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         id  target\n",
            "0         0       1\n",
            "1         2       1\n",
            "2         3       1\n",
            "3         9       1\n",
            "4        11       1\n",
            "...     ...     ...\n",
            "3258  10861       1\n",
            "3259  10865       1\n",
            "3260  10868       1\n",
            "3261  10874       1\n",
            "3262  10875       1\n",
            "\n",
            "[3263 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0VxKrkujwTy",
        "outputId": "ea5c9036-f86c-43a3-9df9-26ac7d6dba20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# to download files stored in Colab\n",
        "files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ea612a51-0190-4071-a0e9-f2157fad58e4\", \"SubmissionV1.csv\", 22746)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}