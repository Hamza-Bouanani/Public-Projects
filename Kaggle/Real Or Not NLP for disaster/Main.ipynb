{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, concatenate , LSTM\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix , f1_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from openpyxl import load_workbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_proba_threshold(y_positive_proba_pred, threshold):\n",
    "    apply_threshold = np.vectorize(lambda x:0 if x< threshold else 1)\n",
    "    return apply_threshold(y_positive_proba_pred)\n",
    "def optimize_binary_threshold(y_proba_pred, y_true, thresholds, metric = 'f1'):\n",
    "    best_score = 0\n",
    "    best_thresh = 0.1\n",
    "    \n",
    "    for thresh in thresholds : \n",
    "        y_pred = apply_proba_threshold(y_proba_pred, thresh)\n",
    "        \n",
    "        score = f1_score(y_pred = y_pred,y_true = y_true)\n",
    "        \n",
    "            \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thresh = thresh\n",
    "    \n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lecture des données ####\n",
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "test = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding chargé\n"
     ]
    }
   ],
   "source": [
    "### embedding ###\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "print('embedding chargé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train[['text','keyword','location']]\n",
    "ytrain = train['target']\n",
    "xtest = test[['text','keyword','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keyword = {}\n",
    "j=0\n",
    "for i in set(train['keyword']):\n",
    "    dict_keyword[i] = j\n",
    "    j+=1\n",
    "dict_location = {}\n",
    "j=0\n",
    "for i in set(train['location']):\n",
    "    dict_location[i] = j\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes :  ['id', 'keyword', 'location', 'text', 'target']\n",
      "Nombre de lignes du set de train :  7613\n",
      "Nombre de lignes du set de test :  3263\n",
      "Les classes sont :  {0, 1}\n"
     ]
    }
   ],
   "source": [
    "### caractéristiques des données ###\n",
    "print(\"Colonnes : \",list(train.columns))\n",
    "print(\"Nombre de lignes du set de train : \", len(train))\n",
    "print(\"Nombre de lignes du set de test : \", len(test))\n",
    "print(\"Les classes sont : \",set(train['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split train into train and validation ###\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(xtrain, ytrain, test_size = 0.3)\n",
    "xtrain_text = np.array(embed(xtrain['text']))\n",
    "xtrain_location = np.array([dict_location[i] for i in xtrain['location']])\n",
    "xtrain_keyword = np.array([dict_keyword[i] for i in xtrain['keyword']])\n",
    "\n",
    "xvalid_text = np.array(embed(xvalid['text']))\n",
    "xvalid_location = np.array([dict_location[i] for i in xvalid['location']])\n",
    "xvalid_keyword = np.array([dict_keyword[i] for i in xvalid['keyword']]) \n",
    "\n",
    "xtest_text = np.array(embed(xtest['text']))\n",
    "xtest_location = []\n",
    "xtest_keyword = []\n",
    "\n",
    "for i in xtest['location']:\n",
    "    if i in dict_location:\n",
    "        xtest_location.append(dict_location[i])\n",
    "    else:\n",
    "        xtest_location.append(0)\n",
    "\n",
    "for i in xtest['keyword']:\n",
    "    if i in dict_keyword:\n",
    "        xtest_keyword.append(dict_keyword[i])\n",
    "    else:\n",
    "        xtest_keyword.append(0)\n",
    "        \n",
    "xtest_location = np.array(xtest_location)\n",
    "xtest_keyword = np.array(xtest_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_xgb = []\n",
    "for i in range(len(xtrain_text)):\n",
    "    m = list(xtrain_text[i])\n",
    "    m.append(xtrain_location[i])\n",
    "    m.append(xtrain_keyword[i])\n",
    "    xtrain_xgb.append(m)\n",
    "xtrain_xgb=np.array(xtrain_xgb)\n",
    "\n",
    "xvalid_xgb = []\n",
    "for i in range(len(xvalid_text)):\n",
    "    m = list(xvalid_text[i])\n",
    "    m.append(xvalid_location[i])\n",
    "    m.append(xvalid_keyword[i])\n",
    "    xvalid_xgb.append(m)\n",
    "xvalid_xgb=np.array(xvalid_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### xgboost model learning####\n",
    "model = XGBClassifier(learning_rate = 0.20, n_estimators=250, max_depth=7)\n",
    "model.fit(xtrain_xgb, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1165  152]\n",
      " [ 263  704]]\n",
      "0.7723532638507954\n"
     ]
    }
   ],
   "source": [
    "### xgboost model predict####\n",
    "\n",
    "\n",
    "y_pred = model.predict(xvalid_xgb)\n",
    "CM = confusion_matrix(y_pred = y_pred,y_true = yvalid)\n",
    "f1 = f1_score(y_pred = y_pred,y_true = yvalid)\n",
    "print(CM)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=20)\n",
    "cb_list=[es]\n",
    "def base_line(n1,n2):\n",
    "    inputs = Input(shape=(512,))\n",
    "    \n",
    "    first_layer = Dense(n1, activation='sigmoid')(inputs)\n",
    "    \n",
    "    first_layer_bis = Dense(n1, activation='relu')(inputs)\n",
    "    \n",
    "    inn = concatenate([first_layer,first_layer_bis,inputs])\n",
    "    \n",
    "    second_layer = Dense(n2, activation='sigmoid')(inn)\n",
    "    \n",
    "    second_layer_bis = Dense(n2, activation='sigmoid')(second_layer)\n",
    "    \n",
    "    out = Dense(1,activation='sigmoid')(second_layer_bis)\n",
    "    \n",
    "    loss_f = 'binary_crossentropy'\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[out])\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=[loss_f],metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(xtrain,ytrain, epochs=200,batch_size=64,callbacks=cb_list,validation_split=0.1)\n",
    "    \n",
    "    return model\n",
    "def b():\n",
    "    inputs_text = Input(shape=(512,))\n",
    "    \n",
    "    inputs_keyword = Input(shape=(1,))\n",
    "    \n",
    "    inputs_location = Input(shape=(1,))\n",
    "\n",
    "    \n",
    "    \n",
    "    first_layer_text = Dense(150, activation='sigmoid')(inputs_text)\n",
    "    \n",
    "    first_layer_keyword = Dense(100, activation='sigmoid')(inputs_keyword)\n",
    "    \n",
    "    first_layer_location = Dense(100, activation='sigmoid')(inputs_location)\n",
    "    \n",
    "    \n",
    "    pre_out = concatenate([first_layer_text,first_layer_keyword,first_layer_location])\n",
    "    \n",
    "    pre_out_out = Dense(100, activation='sigmoid')(pre_out)\n",
    "    \n",
    "    out = Dense(1,activation='sigmoid')(pre_out_out)\n",
    "    \n",
    "    loss_f = 'binary_crossentropy'\n",
    "    \n",
    "    model = Model(inputs=[inputs_text,inputs_keyword,inputs_location], outputs=[out])\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=[loss_f],metrics=['accuracy'])\n",
    "    \n",
    "    model.fit([xtrain_text,xtrain_location,xtrain_keyword],ytrain, epochs=200,batch_size=64,callbacks=cb_list,validation_split=0.1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer dense_85 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.recurrent.LSTM'>. Full input: [<keras.layers.recurrent.LSTM object at 0x0000014841A64688>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m--> 697\u001b[1;33m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.layers.recurrent.LSTM'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-6de1563bf2fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxvalid_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxvalid_location\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxvalid_keyword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-147-a89e62c05f1b>\u001b[0m in \u001b[0;36mb\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mfirst_layer_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mfirst_layer_keyword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_keyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    314\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer dense_85 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.recurrent.LSTM'>. Full input: [<keras.layers.recurrent.LSTM object at 0x0000014841A64688>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "model = b()\n",
    "ypred = model.predict([xvalid_text,xvalid_location,xvalid_keyword])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999\n",
      "0.394\n",
      "[[1149  168]\n",
      " [ 248  719]]\n",
      "0.7756202804746495\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.1+i*0.001 for i in range(900)]\n",
    "print(max(thresholds))\n",
    "thresh = optimize_binary_threshold(ypred, yvalid, thresholds, metric = 'f1')\n",
    "print(thresh)\n",
    "y_pred = apply_proba_threshold(ypred, thresh)\n",
    "CM = confusion_matrix(y_pred = y_pred,y_true = yvalid)\n",
    "f1 = f1_score(y_pred = y_pred,y_true = yvalid)\n",
    "print(CM)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = test['id']\n",
    "predictions = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pred for submission ###\n",
    "idd = test['id']\n",
    "predict = model.predict([xtest_text,xtest_location,xtest_keyword])\n",
    "predictions = apply_proba_threshold(predict, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  target\n",
      "0         0       1\n",
      "1         2       1\n",
      "2         3       1\n",
      "3         9       1\n",
      "4        11       1\n",
      "...     ...     ...\n",
      "3258  10861       1\n",
      "3259  10865       1\n",
      "3260  10868       1\n",
      "3261  10874       1\n",
      "3262  10875       1\n",
      "\n",
      "[3263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "### save data ####\n",
    "path = 'Submission/'\n",
    "file_name = 'SubmissionV0.csv'\n",
    "df = pd.DataFrame(idd)\n",
    "df['target'] = predictions\n",
    "print(df)\n",
    "df.to_csv(path+file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
